{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3314383a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# training.py\n",
    "\n",
    "# Correct the path to the drive path (see the training.ipynb in PlateDetection_training)\n",
    "\n",
    "# üß© Install required packages\n",
    "!pip install -q transformers datasets accelerate torchvision\n",
    "\n",
    "# üß† Imports\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    TrOCRProcessor,\n",
    "    VisionEncoderDecoderModel,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    ")\n",
    "\n",
    "# üì• Load TrOCR model and processor\n",
    "model_name = \"microsoft/trocr-base-stage1\"\n",
    "processor = TrOCRProcessor.from_pretrained(model_name)\n",
    "model = VisionEncoderDecoderModel.from_pretrained(model_name)\n",
    "\n",
    "# üõ†Ô∏è Configure model\n",
    "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "model.config.vocab_size = model.config.decoder.vocab_size\n",
    "model.config.max_length = 16\n",
    "model.config.eos_token_id = processor.tokenizer.sep_token_id\n",
    "\n",
    "# üìÅ Load dataset (adjust paths if needed)\n",
    "data_files = {\n",
    "    \"train\": \"/content/OCR_dataset/train/train_data.json\",\n",
    "    \"validation\": \"/content/OCR_dataset/valid/valid_data.json\"\n",
    "}\n",
    "dataset = load_dataset(\"json\", data_files=data_files)\n",
    "\n",
    "# üîÑ Preprocessing function\n",
    "def preprocess(example):\n",
    "    image = Image.open(example[\"image_path\"]).convert(\"RGB\")\n",
    "    pixel = processor(images=image, return_tensors=\"pt\").pixel_values.squeeze(0)\n",
    "\n",
    "    label_ids = processor.tokenizer(\n",
    "        example[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        max_length=16,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).input_ids.squeeze(0)\n",
    "    label_ids[label_ids == processor.tokenizer.pad_token_id] = -100\n",
    "\n",
    "    return {\"pixel_values\": pixel, \"labels\": label_ids}\n",
    "\n",
    "# ‚öôÔ∏è Preprocess dataset\n",
    "processed_dataset = dataset.map(preprocess, remove_columns=[\"image_path\", \"text\"])\n",
    "\n",
    "# üß© Custom data collator\n",
    "def custom_collate_fn(features):\n",
    "    pixel_values = torch.stack([\n",
    "        torch.tensor(f[\"pixel_values\"]) if not isinstance(f[\"pixel_values\"], torch.Tensor) else f[\"pixel_values\"]\n",
    "        for f in features\n",
    "    ])\n",
    "    labels = torch.nn.utils.rnn.pad_sequence(\n",
    "        [torch.tensor(f[\"labels\"]) if not isinstance(f[\"labels\"], torch.Tensor) else f[\"labels\"]\n",
    "         for f in features],\n",
    "        batch_first=True,\n",
    "        padding_value=-100\n",
    "    )\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "# üõ†Ô∏è Training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./trocr_finetuned\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=5,\n",
    "    predict_with_generate=True,\n",
    "    fp16=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "# üèãÔ∏è‚Äç‚ôÇÔ∏è Initialize Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=processed_dataset[\"train\"],\n",
    "    eval_dataset=processed_dataset[\"validation\"],\n",
    "    data_collator=custom_collate_fn\n",
    ")\n",
    "\n",
    "# üöÄ Start training\n",
    "trainer.train()\n",
    "\n",
    "# üíæ Save fine-tuned model\n",
    "trainer.save_model(\"./trocr_finetuned\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
